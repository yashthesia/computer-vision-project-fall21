{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rawpy\n",
    "from tqdm import tqdm as pbar\n",
    "import copy\n",
    "from livelossplot import PlotLosses\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import cv2\n",
    "seaborn.set()\n",
    "import scipy\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'dataset'\n",
    "train_path = '/Sony_train_list.txt'\n",
    "test_path = '/Sony_test_list.txt'\n",
    "val_path = '/Sony_val_list.txt'\n",
    "# np.random.seed(0)\n",
    "# torch.manual_seed(0)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess raw data from camera sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/3a.png)\n",
    "\n",
    "Pack raw Bayer sensor data into 4 channels (R-G-B-G). By doing this also reduces resolution by factor of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Pack raw is used for input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_raw(raw):\n",
    "    \"\"\"\n",
    "    Input: object returned from rawpy.imread()\n",
    "    Output: numpy array in shape (1424, 2128, 4)\n",
    "    \"\"\"\n",
    "    \n",
    "    im = raw.raw_image_visible.astype(np.float32) # shape of (2848, 4256)\n",
    "    im = np.maximum(im - 512, 0) / (16383 - 512) #subtract the black level\n",
    "    im = np.expand_dims(im, axis=2) # shape of (2848, 4256, 1)\n",
    "\n",
    "    img_shape = im.shape # (H, W, 1)\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "    \n",
    "    # Pack into 4 channels\n",
    "    red = im[0:H:2,0:W:2,:]\n",
    "    green_1 = im[0:H:2,1:W:2,:]\n",
    "    blue = im[1:H:2,1:W:2,:]\n",
    "    green_2 = im[1:H:2,0:W:2,:]\n",
    "    \n",
    "    # Final shape: (1424, 2128, 4)\n",
    "    out = np.concatenate((red, green_1, blue, green_2), axis=2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_img = rawpy.imread(data_path + '/Sony/short/00001_00_0.04s.ARW')\n",
    "# x_img = pack_raw(x_img)\n",
    "# x_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Post process is used for ground true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(raw):\n",
    "    \"\"\"\n",
    "    Input: object returned from rawpy.imgread()\n",
    "    Output: numpy array in shape (2848, 4256, 3)\n",
    "    \"\"\"\n",
    "    max_output = 65535.0\n",
    "    im = raw.postprocess(use_camera_wb=True, no_auto_bright=True, output_bps=16)\n",
    "    im = np.float32(im / max_output)\n",
    "    im = cv2.resize(im, (2128 , 1424), interpolation = cv2.INTER_AREA)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_img = rawpy.imread(data_path + '/Sony/long/00001_00_10s.ARW')\n",
    "# y_img = post_process(y_img)\n",
    "# y_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Batch process all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Files' name explanation**\n",
    "\n",
    "The file lists are provided. In each row, there are a short-exposed image path, the corresponding long-exposed image path, camera ISO and F number. \n",
    "Note that multiple short-exposed images may correspond to the same long-exposed image.\n",
    "\n",
    "The file name contains the image information. For example, in \"10019_00_0.033s.RAF\":\n",
    "- the first digit \"1\" means it is from the test set (\"0\" for training set and \"2\" for validation set)\n",
    "- 0019\" is the image ID\n",
    "- the following \"00\" is the number in the sequence/burst\n",
    "- \"0.033s\" is the exposure time 1/30 seconds.\n",
    "\n",
    "There are some misalignment with the ground-truth for image 10034, 10045, 10172. I've removed those images for quantitative results, but they still can be used for qualitative evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_list(file_list):\n",
    "    data = pd.read_csv(data_path + file_list, sep=\" \", header = None, names = ['X', 'Y', 'ISO', 'F-stop'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = read_file_list('/Sony_train_list.txt')\n",
    "train_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list['Y'].value_counts().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_raw(data, hide_progree=False):\n",
    "    \"\"\"\n",
    "    Input: Pandas dataframe returned from read_file_list\n",
    "    Output: a dictionary of \n",
    "            X : amplified numpy array\n",
    "            Y : numpy array\n",
    "            X_Y_map: numpy array of indexes of corresponding pair of X and Y\n",
    "    \"\"\"\n",
    "    \n",
    "    # Multiple Xs can have the same Y    \n",
    "    m_x = len(data)\n",
    "    m_y = data['Y'].nunique()\n",
    "    \n",
    "    X = np.zeros((m_x, 1424, 2128, 4), dtype=np.float32)\n",
    "    Y = np.zeros((m_y, 1424, 2128, 3), dtype=np.float32)\n",
    "   \n",
    "    # Mapping of of X to Y\n",
    "    X_map = []\n",
    "    Y_map = []\n",
    "    \n",
    "    for i in pbar(range(m_x), disable=hide_progree):\n",
    "        x_path = data.iloc[i][0][1:] # remove the \".\" in the name\n",
    "        y_path = data.iloc[i][1][1:] # remove the \".\" in the name\n",
    "        \n",
    "        # Shutter speed is in the file name\n",
    "        x_shutter_speed = x_path.split('_')[-1].split('s.')[0]\n",
    "        y_shutter_speed = y_path.split('_')[-1].split('s.')[0]\n",
    "        amp_ratio = float(y_shutter_speed)/float(x_shutter_speed)\n",
    "        \n",
    "        X[i] = pack_raw(rawpy.imread(data_path + x_path)) * amp_ratio\n",
    "    \n",
    "    for i in pbar(range(m_y), disable=hide_progree):\n",
    "        current_y = data['Y'].unique()[i]\n",
    "        \n",
    "        y_path = current_y[1:]\n",
    "        Y[i] = post_process(rawpy.imread(data_path + y_path))\n",
    "        \n",
    "        # Maping of X to Y\n",
    "        X_map_temp = data['Y'][data['Y']==current_y].index.tolist()\n",
    "        Y_map_temp = [i]*len(X_map_temp)\n",
    "        X_map += X_map_temp\n",
    "        Y_map += Y_map_temp\n",
    "    \n",
    "    X_Y_map = np.array((X_map, Y_map), dtype=np.int32).T\n",
    "    dataset = {'X':X, 'Y':Y, 'X_Y_map':X_Y_map}\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = batch_process_raw(train_list.head(10), True)\n",
    "print(\"Shape of X_train:\", train_dataset['X'].shape)\n",
    "print(\"Shape of Y_train:\", train_dataset['Y'].shape)\n",
    "print(\"Shape of X_Y_map_train:\", train_dataset['X_Y_map'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['X_Y_map']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Make batches of image patches for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_torch(image):\n",
    "    \"\"\"\n",
    "    Input: numpy array (H x W x C)\n",
    "    Output: torch tensory (C x H x W)\n",
    "    \"\"\"\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    torch_tensor = torch.from_numpy(image)\n",
    "    return torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset class\n",
    "class SeeInTheDarkDataset(Dataset):\n",
    "    def __init__(self, dataset = None, transform = None):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dataset['X_Y_map'].shape[0]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x_index, y_index = self.dataset['X_Y_map'][i][0], self.dataset['X_Y_map'][i][1]\n",
    "        \n",
    "        X, Y = self.dataset['X'][x_index], self.dataset['Y'][y_index]\n",
    "\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=X, mask=Y)\n",
    "            X = transformed['image']\n",
    "            Y = transformed['mask']\n",
    "            X = transforms.ToTensor()(X)\n",
    "            Y = transforms.ToTensor()(Y)\n",
    "            \n",
    "            X = torch.clamp(X, min=0.0, max=1.0)\n",
    "            Y = torch.clamp(Y, min=0.0, max=1.0)  \n",
    "        return X, Y \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/atten_Unet_GAN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "\n",
    "def init_weights(net, init_type='normal', gain=0.02):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            init.normal_(m.weight.data, 1.0, gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out):\n",
    "        super(conv_block,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch_out, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out):\n",
    "        super(up_conv,self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n",
    "\t\t    nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "\n",
    "class Recurrent_block(nn.Module):\n",
    "    def __init__(self,ch_out,t=2):\n",
    "        super(Recurrent_block,self).__init__()\n",
    "        self.t = t\n",
    "        self.ch_out = ch_out\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_out,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n",
    "\t\t    nn.BatchNorm2d(ch_out),\n",
    "\t\t\tnn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        for i in range(self.t):\n",
    "\n",
    "            if i==0:\n",
    "                x1 = self.conv(x)\n",
    "            \n",
    "            x1 = self.conv(x+x1)\n",
    "        return x1\n",
    "        \n",
    "class RRCNN_block(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out,t=2):\n",
    "        super(RRCNN_block,self).__init__()\n",
    "        self.RCNN = nn.Sequential(\n",
    "            Recurrent_block(ch_out,t=t),\n",
    "            Recurrent_block(ch_out,t=t)\n",
    "        )\n",
    "        self.Conv_1x1 = nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.Conv_1x1(x)\n",
    "        x1 = self.RCNN(x)\n",
    "        return x+x1\n",
    "\n",
    "\n",
    "class single_conv(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out):\n",
    "        super(single_conv,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class Attention_block(nn.Module):\n",
    "    def __init__(self,F_g,F_l,F_int):\n",
    "        super(Attention_block,self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "            )\n",
    "        \n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self,g,x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1+x1)\n",
    "        psi = self.psi(psi)\n",
    "\n",
    "        return x*psi\n",
    "\n",
    "\n",
    "class U_Net(nn.Module):\n",
    "    def __init__(self,img_ch=3,output_ch=1):\n",
    "        super(U_Net,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n",
    "        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n",
    "        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n",
    "        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n",
    "        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
    "\n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x1 = self.Conv1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        d5 = torch.cat((x4,d5),dim=1)\n",
    "        \n",
    "        d5 = self.Up_conv5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        return d1\n",
    "\n",
    "\n",
    "class R2U_Net(nn.Module):\n",
    "    def __init__(self,img_ch=3,output_ch=1,t=2):\n",
    "        super(R2U_Net,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.Upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "        self.RRCNN1 = RRCNN_block(ch_in=img_ch,ch_out=64,t=t)\n",
    "\n",
    "        self.RRCNN2 = RRCNN_block(ch_in=64,ch_out=128,t=t)\n",
    "        \n",
    "        self.RRCNN3 = RRCNN_block(ch_in=128,ch_out=256,t=t)\n",
    "        \n",
    "        self.RRCNN4 = RRCNN_block(ch_in=256,ch_out=512,t=t)\n",
    "        \n",
    "        self.RRCNN5 = RRCNN_block(ch_in=512,ch_out=1024,t=t)\n",
    "        \n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512,t=t)\n",
    "        \n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256,t=t)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128,t=t)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64,t=t)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x1 = self.RRCNN1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.RRCNN2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.RRCNN3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.RRCNN4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.RRCNN5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        d5 = torch.cat((x4,d5),dim=1)\n",
    "        d5 = self.Up_RRCNN5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_RRCNN4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_RRCNN3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_RRCNN2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        return d1\n",
    "\n",
    "\n",
    "\n",
    "class AttU_Net(nn.Module):\n",
    "    def __init__(self,img_ch=4,output_ch=3):\n",
    "        super(AttU_Net,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n",
    "        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n",
    "        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n",
    "        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n",
    "        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n",
    "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
    "\n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n",
    "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
    "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
    "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x1 = self.Conv1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        x4 = self.Att5(g=d5,x=x4)\n",
    "        d5 = torch.cat((x4,d5),dim=1)        \n",
    "        d5 = self.Up_conv5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        x3 = self.Att4(g=d4,x=x3)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        x2 = self.Att3(g=d3,x=x2)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        x1 = self.Att2(g=d2,x=x1)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        return d1\n",
    "\n",
    "\n",
    "class R2AttU_Net(nn.Module):\n",
    "    def __init__(self,img_ch=3,output_ch=1,t=2):\n",
    "        super(R2AttU_Net,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.Upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "        self.RRCNN1 = RRCNN_block(ch_in=img_ch,ch_out=64,t=t)\n",
    "\n",
    "        self.RRCNN2 = RRCNN_block(ch_in=64,ch_out=128,t=t)\n",
    "        \n",
    "        self.RRCNN3 = RRCNN_block(ch_in=128,ch_out=256,t=t)\n",
    "        \n",
    "        self.RRCNN4 = RRCNN_block(ch_in=256,ch_out=512,t=t)\n",
    "        \n",
    "        self.RRCNN5 = RRCNN_block(ch_in=512,ch_out=1024,t=t)\n",
    "        \n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n",
    "        self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512,t=t)\n",
    "        \n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n",
    "        self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256,t=t)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
    "        self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128,t=t)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
    "        self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64,t=t)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x1 = self.RRCNN1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.RRCNN2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.RRCNN3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.RRCNN4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.RRCNN5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        x4 = self.Att5(g=d5,x=x4)\n",
    "        d5 = torch.cat((x4,d5),dim=1)\n",
    "        d5 = self.Up_RRCNN5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        x3 = self.Att4(g=d4,x=x3)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_RRCNN4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        x2 = self.Att3(g=d3,x=x2)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_RRCNN3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        x1 = self.Att2(g=d2,x=x1)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_RRCNN2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        return d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, out_channels, 4, stride, 1, bias=False, padding_mode=\"reflect\"\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, x_channels=4, y_channels = 3, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                x_channels + y_channels,\n",
    "                features[0],\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                padding_mode=\"reflect\",\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        in_channels = features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(\n",
    "                CNNBlock(in_channels, feature, stride=1 if feature == features[-1] else 2),\n",
    "            )\n",
    "            in_channels = feature\n",
    "\n",
    "        layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat([x, y], dim=1)\n",
    "        x = self.initial(x)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def Discriminator_test():\n",
    "    x = torch.randn((1, 4, 256, 256))\n",
    "    y = torch.randn((1, 3, 256, 256))\n",
    "    model = Discriminator(x_channels=4, y_channels = 3)\n",
    "    preds = model(x, y)\n",
    "#     print(model)\n",
    "    print(preds.shape)\n",
    "    \n",
    "Discriminator_test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Traing and testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(target, output):\n",
    "    \"\"\"\n",
    "    Calculate Peak Signal To Noise Ratio\n",
    "    Input: torch tensor of shape (m, C, H, W)\n",
    "    Output: average of PSTR for that batch\n",
    "    \"\"\"\n",
    "    \n",
    "    m, C, H, W = target.shape\n",
    "    sum_psnr = 0 \n",
    "    \n",
    "    for i in range(m):\n",
    "        output[i] = torch.clamp(output[i], min=0.0, max=1.0)\n",
    "        mse = torch.sum((target[i] - output[i])**2)/(C*H*W)\n",
    "        psnr =  -10*torch.log10(mse)\n",
    "        sum_psnr += psnr\n",
    "        \n",
    "    return sum_psnr/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using', device, 'to train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "my_transforms = A.Compose([\n",
    "    A.RandomCrop(width=512, height=512),\n",
    "    A.HorizontalFlip(p=0.2),\n",
    "    A.VerticalFlip(p=0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset\n",
    "train_list = read_file_list(train_path)\n",
    "train_data = batch_process_raw(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SeeInTheDarkDataset(dataset = train_data, transform =my_transforms)\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = 16, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "val_list = read_file_list(val_path)\n",
    "val_data = batch_process_raw(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SeeInTheDarkDataset(dataset = val_data, transform =my_transforms)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size = 16, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = next(iter(val_loader))\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 2e-4\n",
    "NUM_WORKERS = 2\n",
    "CHANNELS_IMG = 3\n",
    "L1_LAMBDA = 100\n",
    "LAMBDA_GP = 10\n",
    "NUM_EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def train_fn(\n",
    "    disc, gen, loader, opt_disc, opt_gen, l1_loss, bce, g_scaler, d_scaler,\n",
    "):\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    total = 0 \n",
    "    total_psnr = 0 \n",
    "    for idx, (x, y) in enumerate(loop):\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        # Train Discriminator\n",
    "        with torch.cuda.amp.autocast():\n",
    "            y_fake = gen(x)\n",
    "            D_real = disc(x, y)\n",
    "            D_real_loss = bce(D_real, torch.ones_like(D_real))\n",
    "            D_fake = disc(x, y_fake.detach())\n",
    "            D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n",
    "            D_loss = (D_real_loss + D_fake_loss) / 2\n",
    "\n",
    "        disc.zero_grad()\n",
    "        d_scaler.scale(D_loss).backward()\n",
    "        d_scaler.step(opt_disc)\n",
    "        d_scaler.update()\n",
    "\n",
    "        # Train generator\n",
    "        with torch.cuda.amp.autocast():\n",
    "            D_fake = disc(x, y_fake)\n",
    "            G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n",
    "            L1 = l1_loss(y_fake, y) * L1_LAMBDA\n",
    "            G_loss = G_fake_loss + L1\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        g_scaler.scale(G_loss).backward()\n",
    "        g_scaler.step(opt_gen)\n",
    "        g_scaler.update()\n",
    "        \n",
    "        psnr_batch = calculate_psnr(y_fake.detach(), y.detach()).item()\n",
    "        total += x.shape[0]\n",
    "        total_psnr += psnr_batch*x.shape[0]\n",
    "        \n",
    "        if idx % 1 == 0:\n",
    "            loop.set_postfix(\n",
    "                D_real=torch.sigmoid(D_real).mean().item(),\n",
    "                D_fake=torch.sigmoid(D_fake).mean().item(),\n",
    "                D_psnr = psnr_batch\n",
    "            )\n",
    "            \n",
    "    mean_psnr = total_psnr/total\n",
    "    return mean_psnr\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(gen, loader):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    total = 0 \n",
    "    total_psnr = 0 \n",
    "    gen.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, y) in enumerate(loop):\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                y_fake = gen(x)\n",
    "            psnr_batch = calculate_psnr(y_fake.detach(), y.detach()).item()\n",
    "            total += x.shape[0]\n",
    "            total_psnr += psnr_batch*x.shape[0]\n",
    "            \n",
    "    mean_psnr = total_psnr/total\n",
    "    return mean_psnr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "file_name = 'AttUnetGanSSIM'\n",
    "disc = Discriminator().to(DEVICE)\n",
    "gen = AttU_Net().to(DEVICE)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999),)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "BCE = nn.BCEWithLogitsLoss()\n",
    "L1_LOSS = nn.L1Loss()\n",
    "check_point = 10\n",
    "ms_ssim_module = MS_SSIM(data_range=1, size_average=True, channel=3)\n",
    "\n",
    "g_scaler = torch.cuda.amp.GradScaler()\n",
    "d_scaler = torch.cuda.amp.GradScaler()\n",
    "liveloss = PlotLosses()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    best_model_weights = copy.deepcopy(gen.state_dict())\n",
    "    \n",
    "    plot_logs = {}\n",
    "    train_psnr = train_fn(\n",
    "        disc, gen, train_loader, opt_disc, opt_gen, L1_LOSS, BCE, g_scaler, d_scaler,\n",
    "    )\n",
    "    val_psnr = test_model(gen, val_loader)\n",
    "    \n",
    "    plot_logs['PSNR'] = train_psnr\n",
    "    plot_logs['val_PSNR'] = val_psnr\n",
    "    \n",
    "    liveloss.update(plot_logs)\n",
    "    liveloss.draw()\n",
    "        \n",
    "    print(f'[epoch {epoch}/{NUM_EPOCHS}, TRAIN PSNR={train_psnr}, VAL PSNR={val_psnr}]')\n",
    "    \n",
    "     # Check point\n",
    "    if epoch%check_point==0:\n",
    "        torch.save(best_model_weights, f'trained_model/{file_name}_best_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data['X'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = torch.rand(32, 4, 256, 256)\n",
    "gen = Generator()\n",
    "gen(random_data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "test_list = read_file_list('/Sony_test_list.txt')\n",
    "test_dataset = batch_process_raw(test_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = test_model(gen, test_dataset, hide_progress=False)\n",
    "print('Peak Signal Noise Ratio on test dataset {:.2f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test custom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_an_example(gen, test_list, test_dataset, 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_custom_image(gen, 'custom_images/image_1.arw', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
