{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rawpy\n",
    "from tqdm import tqdm as pbar\n",
    "import copy\n",
    "from livelossplot import PlotLosses\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import cv2\n",
    "seaborn.set()\n",
    "import scipy\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'dataset'\n",
    "train_path = '/Sony_train_list.txt'\n",
    "test_path = '/Sony_test_list.txt'\n",
    "val_path = '/Sony_val_list.txt'\n",
    "# np.random.seed(0)\n",
    "# torch.manual_seed(0)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess raw data from camera sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/3a.png)\n",
    "\n",
    "Pack raw Bayer sensor data into 4 channels (R-G-B-G). By doing this also reduces resolution by factor of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Pack raw is used for input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_raw(raw):\n",
    "    \"\"\"\n",
    "    Input: object returned from rawpy.imread()\n",
    "    Output: numpy array in shape (1424, 2128, 4)\n",
    "    \"\"\"\n",
    "    \n",
    "    im = raw.raw_image_visible.astype(np.float32) # shape of (2848, 4256)\n",
    "    im = np.maximum(im - 512, 0) / (16383 - 512) #subtract the black level\n",
    "    im = np.expand_dims(im, axis=2) # shape of (2848, 4256, 1)\n",
    "\n",
    "    img_shape = im.shape # (H, W, 1)\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "    \n",
    "    # Pack into 4 channels\n",
    "    red = im[0:H:2,0:W:2,:]\n",
    "    green_1 = im[0:H:2,1:W:2,:]\n",
    "    blue = im[1:H:2,1:W:2,:]\n",
    "    green_2 = im[1:H:2,0:W:2,:]\n",
    "    \n",
    "    # Final shape: (1424, 2128, 4)\n",
    "    out = np.concatenate((red, green_1, blue, green_2), axis=2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_img = rawpy.imread(data_path + '/Sony/short/00001_00_0.04s.ARW')\n",
    "# x_img = pack_raw(x_img)\n",
    "# x_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Post process is used for ground true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(raw):\n",
    "    \"\"\"\n",
    "    Input: object returned from rawpy.imgread()\n",
    "    Output: numpy array in shape (2848, 4256, 3)\n",
    "    \"\"\"\n",
    "    max_output = 65535.0\n",
    "    im = raw.postprocess(use_camera_wb=True, no_auto_bright=True, output_bps=16)\n",
    "    im = np.float32(im / max_output)\n",
    "    im = cv2.resize(im, (2128 , 1424), interpolation = cv2.INTER_AREA)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_img = rawpy.imread(data_path + '/Sony/long/00001_00_10s.ARW')\n",
    "# y_img = post_process(y_img)\n",
    "# y_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Batch process all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Files' name explanation**\n",
    "\n",
    "The file lists are provided. In each row, there are a short-exposed image path, the corresponding long-exposed image path, camera ISO and F number. \n",
    "Note that multiple short-exposed images may correspond to the same long-exposed image.\n",
    "\n",
    "The file name contains the image information. For example, in \"10019_00_0.033s.RAF\":\n",
    "- the first digit \"1\" means it is from the test set (\"0\" for training set and \"2\" for validation set)\n",
    "- 0019\" is the image ID\n",
    "- the following \"00\" is the number in the sequence/burst\n",
    "- \"0.033s\" is the exposure time 1/30 seconds.\n",
    "\n",
    "There are some misalignment with the ground-truth for image 10034, 10045, 10172. I've removed those images for quantitative results, but they still can be used for qualitative evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_list(file_list):\n",
    "    data = pd.read_csv(data_path + file_list, sep=\" \", header = None, names = ['X', 'Y', 'ISO', 'F-stop'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = read_file_list('/Sony_train_list.txt')\n",
    "train_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_raw(data, hide_progree=False):\n",
    "    \"\"\"\n",
    "    Input: Pandas dataframe returned from read_file_list\n",
    "    Output: a dictionary of \n",
    "            X : amplified numpy array\n",
    "            Y : numpy array\n",
    "            X_Y_map: numpy array of indexes of corresponding pair of X and Y\n",
    "    \"\"\"\n",
    "    \n",
    "    # Multiple Xs can have the same Y    \n",
    "    m_x = len(data)\n",
    "    m_y = data['Y'].nunique()\n",
    "    \n",
    "    X = np.zeros((m_x, 1424, 2128, 4), dtype=np.float32)\n",
    "    Y = np.zeros((m_y, 1424, 2128, 3), dtype=np.float32)\n",
    "   \n",
    "    # Mapping of of X to Y\n",
    "    X_map = []\n",
    "    Y_map = []\n",
    "    \n",
    "    for i in pbar(range(m_x), disable=hide_progree):\n",
    "        x_path = data.iloc[i][0][1:] # remove the \".\" in the name\n",
    "        y_path = data.iloc[i][1][1:] # remove the \".\" in the name\n",
    "        \n",
    "        # Shutter speed is in the file name\n",
    "        x_shutter_speed = x_path.split('_')[-1].split('s.')[0]\n",
    "        y_shutter_speed = y_path.split('_')[-1].split('s.')[0]\n",
    "        amp_ratio = float(y_shutter_speed)/float(x_shutter_speed)\n",
    "        \n",
    "        X[i] = pack_raw(rawpy.imread(data_path + x_path)) * amp_ratio\n",
    "    \n",
    "    for i in pbar(range(m_y), disable=hide_progree):\n",
    "        current_y = data['Y'].unique()[i]\n",
    "        \n",
    "        y_path = current_y[1:]\n",
    "        Y[i] = post_process(rawpy.imread(data_path + y_path))\n",
    "        \n",
    "        # Maping of X to Y\n",
    "        X_map_temp = data['Y'][data['Y']==current_y].index.tolist()\n",
    "        Y_map_temp = [i]*len(X_map_temp)\n",
    "        X_map += X_map_temp\n",
    "        Y_map += Y_map_temp\n",
    "    \n",
    "    X_Y_map = np.array((X_map, Y_map), dtype=np.int32).T\n",
    "    dataset = {'X':X, 'Y':Y, 'X_Y_map':X_Y_map}\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = batch_process_raw(train_list.head(10), True)\n",
    "print(\"Shape of X_train:\", train_dataset['X'].shape)\n",
    "print(\"Shape of Y_train:\", train_dataset['Y'].shape)\n",
    "print(\"Shape of X_Y_map_train:\", train_dataset['X_Y_map'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['X_Y_map']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data augmentation\n",
    "Random crop, flip, and tranpose data, then amplify the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_torch(image):\n",
    "    \"\"\"\n",
    "    Input: numpy array (H x W x C)\n",
    "    Output: torch tensory (C x H x W)\n",
    "    \"\"\"\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    torch_tensor = torch.from_numpy(image)\n",
    "    return torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "my_transforms = A.Compose([\n",
    "    A.RandomCrop(width=512, height=512),\n",
    "    A.HorizontalFlip(p=0.2),\n",
    "    A.VerticalFlip(p=0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset class\n",
    "class SeeInTheDarkDataset(Dataset):\n",
    "    def __init__(self, dataset = None, transform = None):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dataset['X_Y_map'].shape[0]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x_index, y_index = self.dataset['X_Y_map'][i][0], self.dataset['X_Y_map'][i][1]\n",
    "        \n",
    "        X, Y = self.dataset['X'][x_index], self.dataset['Y'][y_index]\n",
    "\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=X, mask=Y)\n",
    "            X = transformed['image']\n",
    "            Y = transformed['mask']\n",
    "            X = transforms.ToTensor()(X)\n",
    "            Y = transforms.ToTensor()(Y)\n",
    "            \n",
    "            X = torch.clamp(X, min=0.0, max=1.0)\n",
    "            Y = torch.clamp(Y, min=0.0, max=1.0)  \n",
    "        return X, Y \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "class DoubleConv(nn.Module):\n",
    "    #  Conv -> BN -> LReLU -> Conv -> BN -> LReLU\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.LeakyReLU(0.2, inplace=True),)\n",
    "    def forward(self, x):\n",
    "        x = self.f(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_ch, out_ch),)\n",
    "    def forward(self, x):\n",
    "        x = self.f(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    # upsample and concat\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(in_ch, in_ch//2, 2, stride=2)\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.upsample(x1)\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.f = nn.Conv2d(in_ch, out_ch, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.f(x)\n",
    "        return x\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inc = DoubleConv(4, 32)\n",
    "        self.d1 = Down(32, 64)\n",
    "        self.d2 = Down(64, 128)\n",
    "        self.d3 = Down(128, 256)\n",
    "        self.d4 = Down(256, 512)\n",
    "\n",
    "        self.u1 = Up(512, 256)\n",
    "        self.u2 = Up(256, 128)\n",
    "        self.u3 = Up(128, 64)\n",
    "        self.u4 = Up(64, 32)\n",
    "        self.outc = OutConv(32, 3)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.d1(x1)\n",
    "        x3 = self.d2(x2)\n",
    "        x4 = self.d3(x3)\n",
    "        x5 = self.d4(x4)\n",
    "        x = self.u1(x5, x4)\n",
    "        x = self.u2(x, x3)\n",
    "        x = self.u3(x, x2)\n",
    "        x = self.u4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        return x\n",
    "    \n",
    "def test_Unet():\n",
    "    random_dataset = torch.rand(4, 4, 256, 256)\n",
    "    model = Unet()\n",
    "    print('model is defined')\n",
    "    out = model(random_dataset)\n",
    "    print(f'input dim : {random_dataset.shape} & output dim : {out.shape}')\n",
    "    assert out.shape == (4, 3, 256, 256)\n",
    "    \n",
    "test_Unet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/Attension_Unet.png)\n",
    "\n",
    "Attension Unet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "\n",
    "def init_weights(net, init_type='normal', gain=0.02):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            init.normal_(m.weight.data, 1.0, gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out):\n",
    "        super(conv_block,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch_out, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out):\n",
    "        super(up_conv,self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n",
    "\t\t    nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "\n",
    "class Recurrent_block(nn.Module):\n",
    "    def __init__(self,ch_out,t=2):\n",
    "        super(Recurrent_block,self).__init__()\n",
    "        self.t = t\n",
    "        self.ch_out = ch_out\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_out,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n",
    "\t\t    nn.BatchNorm2d(ch_out),\n",
    "\t\t\tnn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        for i in range(self.t):\n",
    "\n",
    "            if i==0:\n",
    "                x1 = self.conv(x)\n",
    "            \n",
    "            x1 = self.conv(x+x1)\n",
    "        return x1\n",
    "        \n",
    "class RRCNN_block(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out,t=2):\n",
    "        super(RRCNN_block,self).__init__()\n",
    "        self.RCNN = nn.Sequential(\n",
    "            Recurrent_block(ch_out,t=t),\n",
    "            Recurrent_block(ch_out,t=t)\n",
    "        )\n",
    "        self.Conv_1x1 = nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.Conv_1x1(x)\n",
    "        x1 = self.RCNN(x)\n",
    "        return x+x1\n",
    "\n",
    "\n",
    "class single_conv(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out):\n",
    "        super(single_conv,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class Attention_block(nn.Module):\n",
    "    def __init__(self,F_g,F_l,F_int):\n",
    "        super(Attention_block,self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "            )\n",
    "        \n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self,g,x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1+x1)\n",
    "        psi = self.psi(psi)\n",
    "\n",
    "        return x*psi\n",
    "\n",
    "\n",
    "class U_Net(nn.Module):\n",
    "    def __init__(self,img_ch=3,output_ch=1):\n",
    "        super(U_Net,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n",
    "        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n",
    "        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n",
    "        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n",
    "        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
    "\n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x1 = self.Conv1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        d5 = torch.cat((x4,d5),dim=1)\n",
    "        \n",
    "        d5 = self.Up_conv5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        return d1\n",
    "\n",
    "\n",
    "class R2U_Net(nn.Module):\n",
    "    def __init__(self,img_ch=3,output_ch=1,t=2):\n",
    "        super(R2U_Net,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.Upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "        self.RRCNN1 = RRCNN_block(ch_in=img_ch,ch_out=64,t=t)\n",
    "\n",
    "        self.RRCNN2 = RRCNN_block(ch_in=64,ch_out=128,t=t)\n",
    "        \n",
    "        self.RRCNN3 = RRCNN_block(ch_in=128,ch_out=256,t=t)\n",
    "        \n",
    "        self.RRCNN4 = RRCNN_block(ch_in=256,ch_out=512,t=t)\n",
    "        \n",
    "        self.RRCNN5 = RRCNN_block(ch_in=512,ch_out=1024,t=t)\n",
    "        \n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512,t=t)\n",
    "        \n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256,t=t)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128,t=t)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64,t=t)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x1 = self.RRCNN1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.RRCNN2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.RRCNN3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.RRCNN4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.RRCNN5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        d5 = torch.cat((x4,d5),dim=1)\n",
    "        d5 = self.Up_RRCNN5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_RRCNN4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_RRCNN3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_RRCNN2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        return d1\n",
    "\n",
    "\n",
    "\n",
    "class AttU_Net(nn.Module):\n",
    "    def __init__(self,img_ch=4,output_ch=3):\n",
    "        super(AttU_Net,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n",
    "        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n",
    "        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n",
    "        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n",
    "        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n",
    "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
    "\n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n",
    "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
    "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
    "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x1 = self.Conv1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        x4 = self.Att5(g=d5,x=x4)\n",
    "        d5 = torch.cat((x4,d5),dim=1)        \n",
    "        d5 = self.Up_conv5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        x3 = self.Att4(g=d4,x=x3)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        x2 = self.Att3(g=d3,x=x2)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        x1 = self.Att2(g=d2,x=x1)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        return d1\n",
    "\n",
    "\n",
    "class R2AttU_Net(nn.Module):\n",
    "    def __init__(self,img_ch=3,output_ch=1,t=2):\n",
    "        super(R2AttU_Net,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.Upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "        self.RRCNN1 = RRCNN_block(ch_in=img_ch,ch_out=64,t=t)\n",
    "\n",
    "        self.RRCNN2 = RRCNN_block(ch_in=64,ch_out=128,t=t)\n",
    "        \n",
    "        self.RRCNN3 = RRCNN_block(ch_in=128,ch_out=256,t=t)\n",
    "        \n",
    "        self.RRCNN4 = RRCNN_block(ch_in=256,ch_out=512,t=t)\n",
    "        \n",
    "        self.RRCNN5 = RRCNN_block(ch_in=512,ch_out=1024,t=t)\n",
    "        \n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n",
    "        self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512,t=t)\n",
    "        \n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n",
    "        self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256,t=t)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
    "        self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128,t=t)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
    "        self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64,t=t)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x1 = self.RRCNN1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.RRCNN2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.RRCNN3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.RRCNN4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.RRCNN5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        x4 = self.Att5(g=d5,x=x4)\n",
    "        d5 = torch.cat((x4,d5),dim=1)\n",
    "        d5 = self.Up_RRCNN5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        x3 = self.Att4(g=d4,x=x3)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_RRCNN4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        x2 = self.Att3(g=d3,x=x2)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_RRCNN3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        x1 = self.Att2(g=d2,x=x1)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_RRCNN2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        return d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Traing and testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(target, output):\n",
    "    \"\"\"\n",
    "    Calculate Peak Signal To Noise Ratio\n",
    "    Input: torch tensor of shape (m, C, H, W)\n",
    "    Output: average of PSTR for that batch\n",
    "    \"\"\"\n",
    "    \n",
    "    m, C, H, W = target.shape\n",
    "    sum_psnr = 0 \n",
    "    \n",
    "    for i in range(m):\n",
    "        output[i] = torch.clamp(output[i], min=0.0, max=1.0)\n",
    "        mse = torch.sum((target[i] - output[i])**2)/(C*H*W)\n",
    "        psnr =  -10*torch.log10(mse)\n",
    "        sum_psnr += psnr\n",
    "        \n",
    "    return sum_psnr/m\n",
    "\n",
    "def calculate_ssim(target, output):\n",
    "    \"\"\"\n",
    "    Calculate SSIM\n",
    "    Input: torch tensor of shape (m, C, H, W)\n",
    "    Output: average of SSIM for that batch\n",
    "    \"\"\"\n",
    "    \n",
    "    m, C, H, W = target.shape\n",
    "    sum_ssim = 0 \n",
    "    \n",
    "    for i in range(m):\n",
    "        output[i] = torch.clamp(output[i], min=0.0, max=1.0)\n",
    "        ssim_out = ssim( target[i:i+1], output[i:i+1], data_range=1, size_average=True)\n",
    "        sum_ssim += ssim_out\n",
    "        \n",
    "    return sum_ssim/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "def train_model(model, train_dataset, train_loader, val_dataset, val_loader, optimizer, scheduler, check_point, batch_size, num_epochs, file_name = ''):\n",
    "    liveloss = PlotLosses()\n",
    "    criterion = nn.L1Loss()\n",
    "    ms_ssim_module = MS_SSIM(data_range=1, size_average=True, channel=3)\n",
    "    \n",
    "    \n",
    "    best_psnr = 0.0\n",
    "    best_ssim = 0.0\n",
    "    \n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in pbar(range(num_epochs)):\n",
    "        plot_logs = {}\n",
    "        logs = []\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'validation']:\n",
    "            psnr_epoch = 0\n",
    "            ssim_epoch = 0 \n",
    "            \n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                m_train = 0 \n",
    "                # Iterate over data\n",
    "                for a_batch_index,(image, target) in pbar(enumerate(train_loader), total = len(train_loader), leave = False):\n",
    "                    \n",
    "                    #load dataset on GPU\n",
    "                    image = image.to(device)\n",
    "                    target = target.to(device)\n",
    "                    \n",
    "                    # Zero gradient\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    y_hat = model(image)\n",
    "                    \n",
    "                    # Calculate loss\n",
    "                    psnr_batch = calculate_psnr(target.detach(), y_hat.detach()).item()\n",
    "                    ssim_batch = calculate_ssim(target.detach(), y_hat.detach()).item()\n",
    "                    \n",
    "                    #comput ssim loss\n",
    "                    L1_loss = criterion(target, y_hat)\n",
    "                    SSIM_loss = 1 -ms_ssim_module( target, y_hat)\n",
    "                    \n",
    "                    loss = L1_loss + SSIM_loss\n",
    "                    \n",
    "                    psnr_epoch += psnr_batch \n",
    "                    ssim_epoch += ssim_batch\n",
    "                    \n",
    "                    m_train+=1\n",
    "                    \n",
    "                    # Backward pass\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                # Update logs\n",
    "                psnr_epoch = psnr_epoch / m_train\n",
    "                ssim_epoch = ssim_epoch / m_train\n",
    "                plot_logs['PSNR'] = psnr_epoch\n",
    "                plot_logs['SSIM'] = psnr_epoch\n",
    "                logs.append(psnr_epoch)\n",
    "                \n",
    "                                    \n",
    "            else:    \n",
    "                val_ssim_epoch, val_psnr_epoch = test_model(model, val_dataset, val_loader)\n",
    "                \n",
    "                # Update logs\n",
    "                plot_logs['val_PSNR'] = val_psnr_epoch\n",
    "                plot_logs['val_SSIM'] = val_ssim_epoch\n",
    "                \n",
    "                logs.append(val_psnr_epoch)\n",
    "                \n",
    "                # Save best model\n",
    "                if val_psnr_epoch > best_psnr:\n",
    "                    best_psnr = val_psnr_epoch\n",
    "                    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "                    \n",
    "                # Check point\n",
    "                if epoch%check_point==0:\n",
    "                    torch.save(best_model_weights, f'trained_model/{file_name}.pt')\n",
    "\n",
    "#         scheduler.step()\n",
    "        \n",
    "        # Update live plot every epoch\n",
    "        liveloss.update(plot_logs)\n",
    "        liveloss.draw()\n",
    "        \n",
    "        # Write to log file every epoch\n",
    "        # Epoch - Best Val PSNR - Train  PSNR - Val PSNR\n",
    "        f = open(f\"trained_model/{file_name}_training_log.txt\", \"a\")\n",
    "        f.write(\"\\n{:4d} \\t{:.5f} \\t{:.5f} \\t{:.5f}\".format(epoch, best_psnr, logs[0], logs[1]))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataset, data_loader):\n",
    "    model.eval()\n",
    "    m_test = len(dataset['X_Y_map'])\n",
    "    test_psnr = 0\n",
    "    test_ssim = 0 \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Iterate over data\n",
    "        for i, (image, target) in enumerate(data_loader):\n",
    "            \n",
    "            #load dataset on GPU\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_hat = model(image)\n",
    "\n",
    "            # Calculate loss\n",
    "            test_psnr_batch = calculate_psnr(target, y_hat).item()\n",
    "            test_ssim_batch = calculate_ssim(target, y_hat).item()\n",
    "            test_ssim += test_ssim_batch * image.size(0)\n",
    "            test_psnr += test_psnr_batch * image.size(0)\n",
    "            \n",
    "    return test_ssim / m_test,test_psnr / m_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def display_custom_image(model, image_path, amp_ratio, render=False, file_name = 'pred'):\n",
    "    model.eval()\n",
    "        \n",
    "    orig_image = post_process(rawpy.imread(image_path))\n",
    "    \n",
    "    fig=plt.figure(figsize=(20, 10))\n",
    "    fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(orig_image, vmin=0, vmax=1)\n",
    "    plt.title('Original image')\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    \n",
    "    \n",
    "    image = pack_raw(rawpy.imread(image_path)) * amp_ratio\n",
    "   \n",
    "    image = numpy_to_torch(np.clip(image, a_min=0.0, a_max=1.0)).unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "    print('->'*10,image.shape)\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(image)\n",
    "        y_hat = torch.clamp(y_hat, min=0.0, max=1.0)\n",
    "    image = y_hat.squeeze().cpu().numpy().transpose((1, 2, 0))\n",
    "        \n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(image, vmin=0, vmax=1)\n",
    "    plt.title('Denoised by model')\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(image, vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.plot()\n",
    "    plt.savefig(f'custom_images/{file_name}.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.imshow(orig_image, vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.plot()\n",
    "    plt.savefig(f'custom_images/original_{file_name}.png')\n",
    "    plt.show()\n",
    "    \n",
    "    random_array = image * 255\n",
    "    random_array = random_array.astype(np.uint8)\n",
    "    random_image = Image.fromarray(random_array)\n",
    "    random_image.save(f'custom_images/processed_{file_name}.png')\n",
    "\n",
    "                \n",
    "    if render:\n",
    "        scipy.misc.toimage(image * 255, high=255, low=0, cmin=0, cmax=255).save(f'custom_images/processed_{file_name}.png')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Put everything together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using', device, 'to train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset\n",
    "train_list = read_file_list(train_path)\n",
    "train_data = batch_process_raw(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SeeInTheDarkDataset(dataset = train_data, transform =my_transforms)\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = 16, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "val_list = read_file_list(val_path)\n",
    "val_data = batch_process_raw(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SeeInTheDarkDataset(dataset = val_data, transform =my_transforms)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size = 16, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = next(iter(val_loader))\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inialize and load model\n",
    "# my_model = Unet()\n",
    "my_model = AttU_Net()\n",
    "# my_model.load_state_dict(torch.load('trained_model/AttU_Net_model.pt',map_location='cuda'))\n",
    "my_model = my_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize optimizer\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=0.0001)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[40, 80], gamma=0.1)\n",
    "\n",
    "# # Train model\n",
    "train_model(my_model,  train_data,train_loader, val_data,val_loader, optimizer, scheduler, check_point=1, num_epochs=100, file_name = 'Unet_with_ssim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "test_list = read_file_list(test_path)\n",
    "test_data = batch_process_raw(test_list)\n",
    "#data augmentation\n",
    "my_transforms = A.Compose([\n",
    "    A.RandomCrop(width=2128, height=1424),\n",
    "#     A.HorizontalFlip(p=0.2),\n",
    "#     A.VerticalFlip(p=0.2)\n",
    "])\n",
    "test_dataset = SeeInTheDarkDataset(dataset = test_data, transform =my_transforms)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 'dataset/Sony/short/image_name'\n",
    "gamma = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this fuction will produce the mask images from the Attention Unet model\n",
    "def display_mask_image(model, image_path, amp_ratio, render=False, file_name = 'pred'):\n",
    "    model.eval()   \n",
    "    orig_image = post_process(rawpy.imread(image_path))\n",
    "    \n",
    "    fig=plt.figure(figsize=(20, 10))\n",
    "    fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(orig_image, vmin=0, vmax=1)\n",
    "    plt.title('Original image')\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    \n",
    "    image = pack_raw(rawpy.imread(image_path)) * amp_ratio\n",
    "   \n",
    "    image = numpy_to_torch(np.clip(image, a_min=0.0, a_max=1.0)).unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "    print('->'*10,image.shape)\n",
    "    with torch.no_grad():\n",
    "       \n",
    "        \n",
    "        activation = {}\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.detach()\n",
    "            return hook\n",
    "        model.Att2.psi.register_forward_hook(get_activation(\"psi_output\"))\n",
    "        y_hat = model(image)\n",
    "        y_hat = activation['psi_output']\n",
    "        \n",
    "        print('Y'*10, y_hat.shape)\n",
    "        y_hat = torch.clamp(y_hat, min=0.0, max=1.0)\n",
    "    image = y_hat.squeeze().squeeze().cpu().numpy()\n",
    "        \n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(image,cmap='gray',vmin=0, vmax=1)\n",
    "    plt.title('Denoised by model')\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.imshow(image,cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.plot()\n",
    "    plt.savefig(f'custom_images/{file_name}.png')\n",
    "   \n",
    "    random_array = image * 255\n",
    "    random_array = random_array.astype(np.uint8)\n",
    "    random_image = Image.fromarray(random_array)\n",
    "    random_image.save(f'custom_images/processed_{file_name}.png')\n",
    "\n",
    "                \n",
    "    if render:\n",
    "        scipy.misc.toimage(image * 255, high=255, low=0, cmin=0, cmax=255).save(f'custom_images/processed_{file_name}.png')\n",
    "\n",
    "    plt.show()\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inialize and load model\n",
    "AttU_model = AttU_Net()\n",
    "AttU_model.load_state_dict(torch.load('trained_model/Atten_Unet.pt',map_location='cuda'))\n",
    "AttU_model= AttU_model.to(device)\n",
    "# print(test_model(AttU_model, test_data, test_loader))\n",
    "display_custom_image(AttU_model, image_name, gamma, file_name ='Atten_Unet')\n",
    "display_mask_image(AttU_model, image_name, gamma, file_name ='attension_Unet_MASK')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
